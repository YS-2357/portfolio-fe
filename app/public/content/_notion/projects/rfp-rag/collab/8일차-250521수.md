---
태그: []
이름: "8일차-250521(수)"
---

# 8일차-250521(수)


## 🗓️ 일자: 250521(수)


## ✍ 작성자: 정영선


---


## ✅ 오늘 할 일


- [x] 리트리버의 문서별 최소/최대 청크 수 보장 로직 마무리

- [x] 리트리버 latency 측정 로깅 구현

- [x] LangSmith 트레이싱 기반 `loader_test`, `embedding_test`, `retrieval_test`, `generator_test`, `rag_pipeline` 스크립트 제작 및 적용

- [x] LangSmith에서 특정 단계 로깅이 누락되는 문제 디버깅

- [x] README의 폴더구조 문단 작성

- [x] OpenAI embedding 모델을 `text-embedding-3-small`에서 `text-embedding-3-large`로 변경 및 임베딩 차원 자동 설정 로직 반영

- [x] 프롬프트 템플릿 개선 방향 검토 (불확실성, 근거 부족 응답에 대한 페널티 조건 보완 고려)

- [x] 서버 공유 캐시 정책 해제 및 각 사용자별 `.bashrc` 환경 초기화

- [x] 캐시 디렉토리 초기화, 공유 디렉토리 제거, 개인 `.cache` 복원

- [x] LLM 질문 예시 수집 및 구성 (보안 요구사항 중심)

- [x] Retriever가 무관 문서를 섞어 반환하는 문제 분석 → 청크 품질에 대한 검토 수행

---


## 🎯 오늘 한 일


1. **청크 분할 품질 개선 및 평가**: 의미 기반 분할 전략의 적절성을 검토하고, 문서의 구조적 단위를 고려한 `section` 기반 splitter를 실험.

1. **LangSmith 연동 고도화**: 단계별 trace 구간 로깅 및 output 추가. generator/retriever는 성공적으로 로깅되나, loader/embedding 로깅이 누락되는 문제를 재현하고 원인 분석을 시도함.

1. **OpenAI 임베딩 변경 및 로직 보강**: `text-embedding-3-large`로 전환하면서 임베딩 차원을 자동으로 판단하는 로직을 추가하여 다중 모델 대응.

1. **retriever 검색 로직 보완**: 유사도 기반 청크 선택 이후, 문서별 최소/최대 청크 수 보장하는 로직 구현 완료.

1. **공유 캐시 해제 및 환경 초기화**: `/opt/shared_cache` 제거, 각 사용자의 `.bashrc` 내 관련 환경 변수 제거, 개인 캐시 복구.

1. **README.md의 폴더 구조 정리 및 개선**: 프로젝트 구성 요소 명확화 및 정리.

1. **프롬프트 페널티 설계 구상**: 근거 부족, 과도한 추론, 문서 미기반 응답에 대한 억제 조건 추가 가능성 검토.

1. **질문 예시 수집**: 보안 요구사항 기반 문서 분석을 토대로 LLM에 입력할 질문 예시 10개 구상 작업 착수.

---


## 🛠️ Issues & Challenges


- **문제 1:** LangSmith에서 특정 단계(`loader_main`, `embedding_main`) trace가 누락되는 현상 → 실행 흐름상 문제 없음에도 로그가 업로드되지 않아 원인 분석 → 로깅할 데이터가 너무 적으면 누락됨.

- **문제 2:** retriever가 관련 없는 문서까지 함께 반환함 → 유사도 기준보다도 청크 품질 및 문서 내 분포 영향으로 판단됨

---


## 💡 Notes & Ideas


- **아이디어 1:** 프롬프트에 청크 인덱스나 출처 문서명을 삽입하면 모델이 응답 시 근거를 명확히 밝히는 데 도움이 될 수 있음

- **아이디어 2:** 청크 내 주요 키워드/요약을 embedding과 함께 저장하면 추후 RAG 응답 보강 시 활용 가능성 있음

---


## 🔄 내일 할 일


- [ ] 노션 작업 기록 정리 및 발표 문서 준비

- [ ] 프롬프트에 청크 인덱스를 명시하도록 로직 수정

- [ ] generator 출력에 근거 문서의 필드(파일명, 기관, 사업명 등)를 함께 표시하도록 후처리 강화

---


## 📝 Reflection


- 오후가 되면 다들 녹초가 된다. 여름이었다.

- 서버 관리는 너무 힘들다. 공유 캐쉬는 공유대로, 개인 캐쉬는 개인대로 문제가 생긴다. 

---


## 🖥️ 코드 스니펫


```python
# 리트리버 내 문서별 최소/최대 청크 수 보장 로직 핵심부
grouped = OrderedDict()
for doc, score in doc_scores:
    fname = doc.metadata.get("파일명")
    if fname not in grouped:
        grouped[fname] = []
    grouped[fname].append((doc, score))

doc_chunk_counter = defaultdict(int)
selected_set = set()
selected_docs = []

for doc, score in doc_scores:
    fname = doc.metadata.get("파일명")
    doc_id = (fname, doc.metadata.get("chunk_idx"))

    if doc_id in selected_set:
        continue

    limit = max_chunks if max_chunks else float("inf")

    if doc_chunk_counter[fname] < max(min_chunks, limit):
        selected_docs.append(doc)
        selected_set.add(doc_id)
        doc_chunk_counter[fname] += 1
```

