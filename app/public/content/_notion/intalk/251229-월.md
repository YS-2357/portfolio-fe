---
태그: []
날짜: "2025-12-29"
이름: "25.12.29 (월)"
---

# 25.12.29 (월)


# 📅 날짜: 25.12.29 (월)


## 🧩 주요 업무


- 전사 OK/Action 미팅 기반으로 각 프로젝트 리드의 **즉시 실행 항목과 OMTM**을 정리하고, 프로젝트 간 의존성과 우선순위 관리 원칙을 재확인함.

- Project6 기준으로 **인톡 파트너스/케어 AI 서비스 MVP 역할 분리**를 확정하고, 파트너스는 “보험 영업 교육용 AI 트레이너/코치”, 케어는 “실시간 보험영업 도우미 AI 가이드”로 정의함.

- PartnersAI 백엔드에서 **용어 사전(TERM) 미션 고도화**를 진행하여 랜덤 출제·공식 정의 표시·평가 프롬프트 개선·테스트/문서 업데이트를 완료함.

- Streamlit UI에서 랜덤 출제 흐름을 세션 상태로 안정화하고, 사이드바 출력 버그(DeltaGenerator 노출)를 수정하여 운영 안정성을 확보함.

- API 스키마에 definition 필드를 도입하여 “공식 정의 기반 평가”가 가능하도록 입력 계약을 확장함.

- 프롬프트 버전 관리와 실험 속도를 높이기 위해 **A/B 테스트 실험 프레임워크(실험 러너, 테스트케이스, 결과 리포트)**를 추가함.

- compare-ai 서비스에서 LangChain 템플릿 변수 오인 문제를 해결하기 위해 **중괄호 이스케이프 처리**를 적용하여 JSON 응답 파싱 안정성을 개선함.

- CI/CD에서 PR 단계의 품질 보장을 위해 **Docker 빌드 검증 Job 추가** 및 dev 브랜치 트리거 확장, Dockerfile에 data 폴더 포함 설정을 반영함.

## 🎯 목표 정리


### 장기 목표


- 파트너스/케어 AI 서비스를 각자의 사용자 여정에 맞게 분리 운영하고, 공통 컴포넌트(로깅·프롬프트·실험·CI)를 재사용 가능한 형태로 정착시키는 목표 설정함.

- 미션형 학습/코칭 기능의 품질을 객관 지표로 관리하는 실험 체계를 구축하는 목표 설정함.

### 단기 목표


- 파트너스 AI 서비스 MVP의 OMTM인 “AI 서비스 제작 완료”를 위해 핵심 모듈 단위 완료 정의(DoD)와 배포 경로를 고정하는 목표 설정함.

- 용어 미션을 기준으로 프롬프트 버전업(0.2.0) 성능을 실험 리포트로 비교하고, 기준선 대비 개선 폭을 수치로 확정하는 목표 설정함.

## ⚙️ 진행 및 이슈


- **조직 운영/회의 실행**

- **PartnersAI 기능 고도화**

- **운영 안정화**

- **품질/배포 체계 개선**

- **미해결 과제**

## 🧠 느낀 점 및 개선


- 단일 기능 개선보다 “스키마-프롬프트-테스트-문서-CI”의 일관된 변경 관리가 품질을 좌우한다는 점을 재확인함.

- 끝까지 최선을 다하는 태도를 유지하기 위해, 일 단위 산출물의 완료 정의를 더 작게 쪼개고 즉시 검증 루프를 강화할 필요를 인식함.

## 🤝 협업 및 커뮤니케이션


- 각 프로젝트 리드별 OMTM과 가설을 명시하고, 팀 전체 기준 질문(회사 전체 속도에 기여 여부)을 실행 판단의 기준으로 재확인함.

- Project6에서 파트너스/케어 AI 서비스 책임자를 분리하여 의사결정 지연과 중복 실행 가능성을 축소함.

- A1 리드가 제안한 주간 우선순위 합의(Top3) 및 완수율 리포트 체계를 향후 진행 관리의 기본 틀로 공유함.

## 📚 참고 및 학습 내용


- Streamlit session_state를 활용한 UI 상태 관리 패턴 적용함.

- FastAPI/Pydantic 스키마 확장과 프롬프트 템플릿 동기화 방식 정리함.

- LangChain 템플릿 변수 파싱 특성에 대한 우회(중괄호 이스케이프) 적용함.

- GitHub Actions에서 test/lint 이후 Docker 빌드 검증을 연결하는 파이프라인 구성 학습함.

## 📈 성과 및 지표


- Term 미션 고도화 기능 배포 수준 변경 완료: 랜덤 출제, 공식 정의 표시, 프롬프트 반영, 문서/Swagger 업데이트 완료함.

- 테스트 34→36 통과로 계약 변경 안정성 확보함.

- 커밋 5건(기능/문서/CI/실험 프레임워크) 단위로 변경 사항을 추적 가능하게 정리함.

- 프롬프트 실험 프레임워크 구축으로 버전 비교 결과를 JSON/Markdown 리포트로 표준화할 준비 완료함.

## 🗓️ 내일 계획


- term 프롬프트 0.1.0 vs 0.2.0 A/B 실험 실행 후 평균 점수·통과율 리포트 산출함.

- 다른 미션(Structure/Judgment)에도 실험 러너 구조를 확장하고 테스트케이스 형식을 통일함.

- 파트너스/케어 AI 서비스 MVP의 기능 목록을 DoD 기준으로 재정의하고, 배포 경로(백엔드/스트림릿/웹앱)와 운영 상한선(범위·기간)을 문서로 고정함.

```markdown
당신은 ‘업무일지와 회고 정리 전문가’다.  
아래 사용자의 입력을 바탕으로 하루치 업무일지를 Markdown 형식으로 작성하라.  
입력이 비어 있으면 디폴트 예시 내용을 넣는다.  
결과는 실제 업무 문서에 기록 가능한 수준의 정확성·간결성을 유지하라.

---

입력 형식:
[업무 내용]
1. 회의 내용
"""
OK, Action 
30분
* 각 프로젝트 담당자; 바로 OK, Action 하기
30분간 바로 Action <AI 활용 필수 >  
진행시 애로사항 팀 리드에게 공유
(1월 1주차)
A0: 외부 영업
A0 Lead 유인창

@유인창
외부 핵심인재 모셔오기 Head   ;  
유응준 12.31 엔비디아 코리아(전 오라클 상무) 영입
            조용우 12.30 14:00 고객 x 마케팅x 서포터즈 관련 미팅


프로젝트 리드 핵심: 
팀 전체 상황에 대해 이해하고
팀에 진정으로 도움이 되는 방향으로 실행



“팀 상황을 정확히 이해하고 핵심결과를 도출하도록 
인사, 경영, 내부 지원하는 팀 리드와 함께
 
외부 멘토, 이사진, Head 관리를 통해 기업가치 올리기”
A1: 프로젝트 간 싱크 맞추기 및 지원
A1 Lead 유하민

@유하민
1. 프로젝트 간 싱크 맞추기 및 지원
각 프로젝트 현재 상태 파악 (진행률, 블로커, 다음 마일스톤)
프로젝트 간 의존성 맵핑 (A 끝나야 B 시작 가능한 것들)
각 담당자별 현재 작업 내용 확인
공유 리소스 충돌 여부 체크 (디자이너, 개발자 등)
2. 각 인원의 작업 중요도/우선순위 판단
우선순위 프레임워크
아이젠하워 매트릭스 적용 (긴급/중요 2x2)
데드라인 역산해서 버퍼 확보
판단 기준 수립
"이번 주 안에 안 되면 문제 되는 것" 리스트
의존성 있는 작업 먼저 (다른 사람 기다리게 하는 것)
매주 월요일 주간 우선순위 정렬
각 인원과 1:1로 우선순위 합의
"No" 할 수 있는 기준 만들기
각 인원별 이번 주 Top 3 태스크 공유
예상 소요 시간 vs 실제 소요 시간 트래킹
3. 프로젝트 완수율 관리
측정 지표 정의
완수율 = 완료 태스크 / 계획 태스크
예상 일정 vs 실제 일정 차이
스코프 크립 (범위가 계속 늘어남)
리소스 부족 / 다른 프로젝트에 뺏김
요구사항 불명확 → 재작업
외부 의존성 (API, 디자인 등)
개선 액션
스코프 확정 후 변경 시 공식 승인 프로세스
버퍼 타임 기본 20% 확보
작은 단위로 쪼개서 중간 체크포인트
완료 정의(DoD) 명확히 (QA 완료? 배포 완료?)
회고 미팅에서 지연 원인 분석
리포팅
주간 완수율 리포트 (대표 공유)
지연 프로젝트 원인 + 해결 방안 같이 보고
다음 주 예상 완수율 예측



프로젝트 1
Project 1 Lead 김건

@김건
1. 해피톡 문의자 대상: "즉각적 가치 체감 및 자동화"
상담 시나리오의 표준화 (The Hooking Script):
"무엇인가요?"라는 질문에 서비스 설명부터 하지 마세요. [문제 제기 + 해결책 + 증거] 순으로 답변을 미리 세팅하세요.
예: "인톡 파트너스는 [설계사님의 DB 부족/영업 효율 저하] 문제를 해결하는 솔루션입니다. 이미 OO명의 파트너가 월 평균 O%의 성장을 경험하고 계세요."
'무료 진단' 또는 '샘플 자료' 배포 (Lead Magnet):
질문에 답해주는 대신, "지금 바로 적용 가능한 [인톡 파트너스 활용 영업 가이드북]을 보내드릴 테니 읽어보시겠어요?"라며 자료를 먼저 던져주세요. 자료 마지막 페이지에 신청 폼 링크를 삽입합니다.
해피톡 웰컴 메시지 내 '버튼형 FAQ' 배치:
상담원이 개입하기 전, [성공 사례 보기] / [수익 모델 확인하기] / [1분 만에 신청하기]와 같은 버튼을 배치하여 스스로 정보를 소비하고 신청 폼으로 넘어가게 유도합니다.
조건부 혜택 제안 (Scarcity):
상담 마무리 단계에서 "현재 이번 주 파트너십 티오가 3석 남았습니다. 지금 신청 폼을 작성해 두셔야 우선순위 배정이 가능합니다"라는 희소성 메시지를 전달하세요.
2. 오픈채팅방 리드 대상: "소속감과 신뢰의 누적"
'신청 완료' 인증 이벤트:
"오늘 인톡 파트너스 신청 폼 제출하신 분들께만 드리는 특별 부록"을 공지로 띄우고, 채팅방 내에서 신청 완료 인증을 유도하세요. (군중 심리 활용)
정기적인 '성과 스포일러':
매일 혹은 매주 특정 시간에 "실제 인톡 파트너스 가입 후 이번 주에 터진 대박 사례"를 아주 짧고 강렬하게 공유하세요. (이미지 1장 + 텍스트 3줄)
채팅방 전용 '패스트트랙' 링크:
"오픈채팅방 멤버분들만 상담 대기 없이 바로 검토되는 전용 신청 링크입니다"라며 특별 대우를 받는다는 느낌을 주세요.
Q&A 라이브 세션 (또는 텍스트 라이브):
특정 시간대(예: 목요일 저녁 8시)를 정해 "인톡 파트너스에 대해 무엇이든 물어보세요" 타임을 운영하고, 답변 끝에 자연스럽게 "더 자세한 검토는 신청 폼을 통해 가능합니다"라고 안내하세요.
3. 공통 적용: 신청 폼 제출 허들을 낮추는 장치
2단계 신청 구조 (Progressive Profiling):
처음부터 복잡한 정보를 묻지 마세요. 이름과 연락처만 적는 '간편 신청'을 먼저 받고, 그 후 상세 페이지에서 추가 정보를 입력하게 만드세요.
신청 폼 상단에 '혜택 재강조':
폼 상단 이미지에 "인톡 파트너스 합류 시 얻게 될 3가지 이점"을 다시 한번 명시하여 작성 의지를 고취하세요.
리타겟팅 장치 (카카오 알림톡):
해피톡으로 문의는 남겼으나 신청 폼을 안 쓴 사람들에게 24시간 뒤 자동 알림톡을 발송하세요. "어제 문의하신 내용 관련하여 도움이 되셨나요? 현재 신청이 몰리고 있어 확인 부탁드립니다."
OMTM: 리드 대비 신청폼 제출 전환율
Bottom-line 목표 : 
프로젝트2
 


Project 2 Lead 이소영

@이소영


콘텐츠  점검
후킹 점검
조회수 상·하위 콘텐츠 패턴 분석
현재 어떤 소재가 즉각적인 관심을 끌고 있는지 확인하기
경쟁사 벤치마킹: 메리츠 파트너스 블로그 등 참고하여
실제 반응을 얻는 글의 톤·서술 방식·구조 중심 분석

CTA 실험
채널별 조회수는 대폭 증가했으나, 카카오 채널/인톡 파트너스로의 유입이 증명되지 않음
유입을 가로막는 지점(CTA 클릭)을 단일 가설로 설정하고 CTA 구조 및 문구를 집중 실험
위 점검 결과 토대로 프롬프트 수정 반복



지속적인 콘텐츠 제작 및 공유
블로그 발행 + 나머지 채널 공유
네이버 카페 등 커뮤니티 공유

성과 기록
채널별 발행 수, 조회 반응, 유입 여부를 기록하기
단순 수치 나열보다는 왜 이런 결과가 나왔는지 해석이 필요
성과 평가는 숫자의 크기보다 유입 흐름이 만들어졌는지 중심으로 확인

프로젝트 OMTM: 콘텐츠 내 CTA 링크 클릭 발생 여부

가설설정: ‘콘텐츠 내 CTA 링크 클릭 수’를 기준으로 BL, TL까지 목표를 세워 블로그 콘텐츠 내 CTA 링크 클릭이 증가할 경우, 카카오 채널 또는 인톡 파트너스로의 유입이 실제로 발생했음을 확인한다. 
-> BL까지 블로그 콘텐츠 내 CTA 링크 클릭이 5건 이상 발생할 경우,
온드 미디어에서 카카오 채널 또는 인톡 파트너스로의 유입이 구조적으로 가능함을 입증할 수 있다.


프로젝트 3





Project 3 Lead 김승준

@김승준

인톡 파트너스 백엔드 작업 진행
모듈 단위로 작업을 진행, 문서화 작업까지 완료 할 경우 다음 작업 진행하는 방향으로 진행 예정
TL까지 백엔드 완료 목표
개발 서버 docker로 제작 완료
우선 순위:
인증/ 로깅 미들웨어 (진행 중)
로그인 회원가입 모듈
레벨 시스템
미션 시스템
AI 시스템(용어 설명, 말투 교정 등 모듈 내 배치)
인톡 케어 연결 시스템
 
인톡 파트너스 프론트 작업 진행
백엔드 작업이 완료되는 시점부터 진행할 예정
디자인은 배우면서 UI/UX 디자인 시스템 설계부터 진행하며 한 페이지 설계가 끝나면 해당 페이지 프론트 작업을 진행하는 방향으로 진행
우선 순위:
로그인/ 회원가입
메인 페이지
미션 페이지
마이 페이지
랜딩 페이지
인톡 케어 연결 페이지
성과 기록
각 파트에서 정해둔 우선순위 및 작업 목표량과 비교해 미흡 도달 판정
BL까지 완성률

가설: 인톡 파트너스 2.0 배포 시 일 5명이 케어로 연결될 것이다.

OMTM: 백엔드 미션 시스템 제작 완료
프로젝트 4


Project 4 Lead 임정빈
@임정빈

인톡 케어 쿠키 마이그레이션
백엔드 api gateway 커스텀 도메인 설정
같은 root 도메인을 공유하여 first-party cookie로 인식되도록 변경

인톡 케어 모바일 구현
온보딩 관리, 마이페이지 우선 구현




가설: 사용자들이 모바일로 더욱 편리하게 접속 가능

OMTM: 모바일 이용

가설설정: 회원가입을 (예시)
프로젝트 5



Project 5 Lead 배민지
@배민지
현재 상황 (Status)
* 오픈채팅방 신규 유입: 0명
* 당근 비즈니스 게시글 반응: 조회 대비 문의·전환 없음
---
이번 주 실행 계획 (Action Plan)
* 화요일: 오후 출근자 대상 전단지 배포
* 수요일: 오전 출근자 대상 전단지 배포 마무리 -> 건님
* 목요일: 1월 1일 휴무
* 금요일: 이벤트 당첨자 선정 및 공지
---
OMTM (One Metric That Matters)
* 파트너스 신규 유입수 증가를 위한 장치 설치
가설: 인톡 파트너스 오픈채팅방 신규유입이 증가할것이다.
---
주요 과제 (To-Do)
1. 당근 비즈니스 모집 공고문 개선
* 타겟·메시지·CTA 재정의
* 단순 홍보 → 참여/혜택/행동 유도형 구조로 수정

2. 저비용·고효율 마케팅 아이템 서칭
* 예: QR 참여형 전단, 미니 이벤트, 퀴즈/체크리스트, 소액 리워드 등
* 목적: 리드 전환 구조가 있는 아이템 발굴

3. 신규 테스트: 게시판·엘리베이터 포스터
* 오피스 부착 가능 여부 사전 확인
* 가능 시:
* QR 중심의 심플 포스터 시안 제작 및 테스트 배포 검토
—
프로젝트 6

Project 6 Lead 정영선
@정영선

인톡 파트너스/케어 AI서비스 MVP 제작
파트너스: 보험 영업 교육용 AI 트레이너/코치 - 정영선
케어: 실시간 보험영업 도우미 AI 가이드 - 정연우

OMTM: 인톡 파트너스 2.0 AI 서비스 제작 완료

가설: 
프로젝트 7

Project 7 Lead 정수민
OMTM : 주간 파트너스 가입자 10명 확보하기

① 프로젝트 현황 대시보드 형태로 구현
② 각 프로젝트 지표/가설 설정 돕기
③ 회의시간 효율화 (회의 템플릿)

현황 - 본격적인 메타 광고 활성화
25~28일간의 측정

-> Looker Studio를 통한 대시보드 구현 ~ 현황 공개
-> 구성원들이 편하게 현재 성과를 볼 수 있게

Action : 주간 회의 시 '데이터 리뷰' 
회의 시 지난 실험(가설)의 '성공/실패 데이터'를 리뷰합니다.
성공한 실험은 시스템에 반영하고, 
실패한 실험은 "왜 실패했는가?"라는 인사이트를 기록
하여 자산으로 남기기기
Action : OMTM 연동 성과 지표(Dashboard-to-Action)
OMTM 미달 시, 효과적일 수 있는 인사이트 탐구.
회의 및 가설 설정에 반영 될 수 있게 근거 세팅.


프로젝트 8 AI툴 개선

핵심 작업
케어 파트너스용 AI툴 개선
산출물
AI 기능개선 백로그
Project 8 Lead 정연우
@정연우

인톡에서 현재 사용하는 AI툴 정리 및 개선/발전 할 점 탐색
개선점 정리해서 난이도, 기대효과, 중요도 정리

롤플레이 AI 관련해서 방향성 support
영선님 보조해서 scriptmate-be 개발
클로바 스피치로 받아지는 실시간 음성을 텍스트로 바꾸고, 이 텍스트를 llm에 넘기는 과정까지
"""
2. 코드 업무
"""
# 2025-12-29 작업 일지

## 개요
PartnersAI 백엔드 프로젝트 - 용어 사전 기능 고도화 및 UI 개선

---

## 1. Term Mission UI 개선 (Streamlit)

### 1.1 랜덤 용어 출제 버튼 추가
**파일**: `streamlit_app.py`

```python
# 세션 상태 초기화
if "random_term" not in st.session_state:
    st.session_state.random_term = None

# 랜덤 용어 출제 버튼
col1, col2 = st.columns([1, 3])
with col1:
    if st.button("🎲 랜덤 용어 출제", type="primary", use_container_width=True):
        r = httpx.get(f"{API_BASE}/term/random", timeout=10)
        if r.status_code == 200:
            st.session_state.random_term = data["data"]
```

**기능**:
- `GET /ai/term/random` API 호출
- `st.session_state`로 출제된 용어 저장
- 출제 용어가 평가 폼에 자동 입력

### 1.2 공식 정의 표시
```python
if st.session_state.random_term:
    term_data = st.session_state.random_term
    st.info(f"**출제 용어**: {term_data['term']}")
    with st.expander("📖 공식 정의 보기", expanded=False):
        st.write(term_data["definition"])
```

### 1.3 사이드바 버그 수정
**문제**: DeltaGenerator 객체가 화면에 출력됨
```
DeltaGenerator(_root_container=1, _provided_cursor=LockedCursor...
```

**원인**: 삼항 연산자가 반환값을 출력
```python
# Before (버그)
st.success("서버 정상") if r.status_code == 200 else st.error("서버 응답 이상")
```

**해결**:
```python
# After (수정)
if r.status_code == 200:
    st.success("서버 정상")
else:
    st.error("서버 응답 이상")
```

---

## 2. API 스키마 변경

### 2.1 TermRequest에 definition 필드 추가
**파일**: `app/features/term/schemas.py`

```python
class TermRequest(BaseModel):
    term: str = Field(...)
    definition: Optional[str] = Field(
        default=None,
        description="용어의 공식 정의 (랜덤 출제 시 자동 포함)",
        examples=["보험계약의 해지 시에 계약자에게 환급하는 금액"]
    )
    user_explanation: str = Field(...)
```

**목적**: 랜덤 출제된 용어의 공식 정의를 LLM 평가에 활용

### 2.2 서비스 레이어 수정
**파일**: `app/features/term/service.py`

```python
format_result = format_prompt(
    prompt_result.data,
    term=request.term,
    definition=request.definition or "(정의 미제공)",  # 추가
    user_explanation=request.user_explanation
)
```

---

## 3. 프롬프트 템플릿 수정

**파일**: `prompts/term/evaluate_0.1.0.md`

```markdown
# 2. 입력

## 보험 용어
{term}

## 공식 정의        ← 신규 추가
{definition}

## 사용자 설명
{user_explanation}
```

**효과**: LLM이 정확성 평가 시 공식 정의를 참조할 수 있음

---

## 4. 문서 업데이트

### 4.1 README.md 업데이트

**추가된 섹션**:
```markdown
### 용어 사전

| 기능 | 설명 | 엔드포인트 |
|------|------|-----------|
| **랜덤 용어 출제** | 235개 건강보험 용어 중 랜덤 출제 | `GET /ai/term/random` |

- 용어 사전: `data/health_terms_utf8.csv` (건강보험심사평가원 제공)
- 랜덤 출제 시 `definition` 필드가 함께 반환되며, 평가 요청 시 전달하면 정확성 평가에 활용
```

**프로젝트 구조 업데이트**:
```
├── app/
│   ├── services/              # 서비스 (term_bank) ← 추가
├── data/                      # 데이터 파일 ← 추가
│   └── health_terms_utf8.csv  # 건강보험 용어 사전 (235개)
├── tests/                     # 테스트 코드 ← 추가
```

### 4.2 Swagger UI 업데이트
**파일**: `app/main.py`

```markdown
### 📚 용어 사전

| API | 설명 |
|-----|------|
| `GET /ai/term/random` | 235개 건강보험 용어 중 랜덤 출제 |

용어 미션 평가 시 `definition` 필드로 공식 정의를 전달하면 LLM이 정확성 평가에 활용합니다.
```

---

## 5. 테스트 추가

### 5.1 스키마 테스트
**파일**: `tests/test_features/test_term.py`

```python
def test_term_request_with_definition():
    """definition 필드 포함 요청"""
    request = TermRequest(
        term="해약환급금",
        definition="보험계약의 해지 시에 계약자에게 환급하는 금액",
        user_explanation="보험을 중간에 그만두시면 돌려받는 돈이에요."
    )
    assert request.definition == "보험계약의 해지 시에 계약자에게 환급하는 금액"
```

### 5.2 API 테스트
**파일**: `tests/test_api.py`

```python
def test_term_evaluate_with_definition(client):
    """Term 평가 - definition 필드 포함 (스키마 검증)"""
    response = client.post("/ai/term/evaluate", json={
        "term": "해약환급금",
        "definition": "보험계약의 해지 시에 계약자에게 환급하는 금액",
        "user_explanation": ""
    })
    assert response.status_code == 400
    assert "E103" in data["error_code"]
```

### 5.3 테스트 결과
```
34 → 36개 테스트 통과
```

---

## 6. Git 커밋 내역

| 커밋 | 메시지 | 변경 파일 |
|------|--------|-----------|
| `7d4f3e1` | feat: Term 미션 UI 개선 및 공식 정의 프롬프트 포함 | 4개 |
| `dfd88da` | docs: README/Swagger 최신화 및 테스트 추가 | 5개 |

### 커밋 1: `7d4f3e1`
```
feat: Term 미션 UI 개선 및 공식 정의 프롬프트 포함

- streamlit_app.py: 랜덤 용어 출제 버튼 추가 (🎲)
  - session_state로 출제 용어 저장
  - 공식 정의 expander로 표시
  - 출제된 용어 자동 입력
- schemas.py: TermRequest에 definition 필드 추가 (Optional)
- service.py: format_prompt에 definition 전달
- prompts/term/evaluate_0.1.0.md: 공식 정의 섹션 추가
  - LLM이 정확성 평가 시 공식 정의 참조
```

### 커밋 2: `dfd88da`
```
docs: README/Swagger 최신화 및 테스트 추가

## 문서 업데이트
- README.md: 용어 사전 섹션, 프로젝트 구조 (data/, services/)
- Swagger UI: 용어 사전 API 설명, definition 필드 안내

## 테스트 추가 (34 → 36)
- test_term_request_with_definition: definition 필드 스키마
- test_term_evaluate_with_definition: API definition 파라미터

## 버그 수정
- streamlit_app.py: 사이드바 삼항연산자 → if/else (DeltaGenerator 출력 방지)
```

---

## 7. 기타 작업

### 7.1 포트 충돌 해결
**문제**: 포트 8000, 8501 이미 사용 중
```
ERROR: [Errno 10048] error while attempting to bind on address ('127.0.0.1', 8000)
```

**해결**:
```powershell
# 프로세스 확인
Get-NetTCPConnection -LocalPort 8000,8501 | Select-Object LocalPort, OwningProcess

# 프로세스 종료
Stop-Process -Id 2764,19660 -Force
```

### 7.2 compare-ai 프로젝트 버그 수정
**파일**: `compare-ai/app/services/prompt_compare/evaluator.py`

**문제**: LLM 응답의 JSON `{"passed": true}`를 LangChain이 템플릿 변수로 오인
```
Input to ChatPromptTemplate is missing variables {'question', '\n    "passed"'}
```

**해결**: 모든 동적 값의 중괄호 이스케이프
```python
safe_question = question.replace("{", "{{").replace("}", "}}")
safe_prompt_text = prompt_text.replace("{", "{{").replace("}", "}}")
safe_examples = examples.replace("{", "{{").replace("}", "}}")
```

---

## 8. CI/CD 개선

### 8.1 Docker 빌드 검증 추가
**파일**: `.github/workflows/ci.yml`

```yaml
docker:
  runs-on: ubuntu-latest
  needs: [test, lint]  # test, lint 통과 후 실행
  steps:
    - uses: actions/checkout@v4
    - name: Build Docker image
      run: docker build -t partnersai:${{ github.sha }} .
```

**목적**: PR 단계에서 Docker 이미지 빌드 검증 (push 없이 빌드만)

### 8.2 Dockerfile 수정
```dockerfile
COPY data/ ./data/  # 용어 사전 CSV 포함
```

### 8.3 브랜치 전략
**CI 트리거 설정**:
```yaml
on:
  push:
    branches: [main, master, develop, dev]  # dev 추가
  pull_request:
    branches: [main, master]
```

**워크플로우**:
- `dev` 브랜치에서 개발
- PR로 `main`에 병합
- main 브랜치 보호 규칙 설정 (GitHub Settings > Branches)

---

## 9. 프롬프트 실험 프레임워크

### 9.1 폴더 구조
```
experiments/
├── run_experiment.py          # A/B 테스트 러너
├── test_cases/
│   └── term_test_cases.json   # 10개 테스트 케이스
├── results/                   # 결과 자동 저장
│   ├── *.json                 # 상세 데이터
│   └── *.md                   # Markdown 리포트
└── README.md                  # 사용법

prompts/
├── EXPERIMENTS.md             # 실험 기록 템플릿
└── term/
    ├── evaluate_0.1.0.md      # 기준선
    └── evaluate_0.2.0.md      # Few-shot 예시 추가 버전
```

### 9.2 실험 러너 기능
**파일**: `experiments/run_experiment.py`

**CLI 사용법**:
```bash
# A/B 비교 테스트
python experiments/run_experiment.py -f term -a 0.1.0 -b 0.2.0

# 단일 버전 테스트
python experiments/run_experiment.py -f term -a 0.1.0

# 도움말
python experiments/run_experiment.py --help
```

**주요 기능**:
- `argparse` CLI (-f feature, -a version_a, -b version_b)
- `asyncio.gather()` 병렬 실행 (속도 개선)
- JSON + Markdown 결과 파일 자동 생성
- 다중 feature 지원 (term, structure, judgment)

### 9.3 테스트 케이스 형식
**파일**: `experiments/test_cases/term_test_cases.json`

```json
{
  "id": "term_001",
  "term": "해약환급금",
  "definition": "보험계약의 해지 시에 계약자에게 환급하는 금액",
  "user_explanation": "적금 중간에 깨면 이자 일부를 못 받듯이...",
  "expected_score_range": [0.8, 1.0],
  "notes": "우수 답변 예시"
}
```

### 9.4 프롬프트 버전 0.2.0
**파일**: `prompts/term/evaluate_0.2.0.md`

**변경사항**: Few-shot 예시 3개 추가
```markdown
# 4. 평가 예시

## 예시 1: 우수 (0.9점)
- 용어: 해약환급금
- 설명: "적금 중간에 깨면 이자 일부를 못 받잖아요?..."
- 이유: 적금 비유로 친숙하게 설명, 초기 저환급 명시

## 예시 2: 보통 (0.6점)
...

## 예시 3: 미흡 (0.25점)
...
```

### 9.5 Markdown 리포트 출력 예시
```markdown
# 프롬프트 실험 리포트

## 1. 결과 요약
| 메트릭 | 0.1.0 | 0.2.0 | 차이 |
|--------|-------|-------|------|
| 평균 점수 | 0.650 | 0.720 | +0.070 |
| 통과율 | 60.0% | 80.0% | +20.0% |

## 2. 케이스별 상세 결과
| # | Case ID | 0.1.0 | 0.2.0 | 차이 |
|---|---------|-------|-------|------|
| 1 | term_001 | ✅0.85 | ✅0.90 | 🔺+0.05 |

## 3. 프롬프트 비교
[두 버전 전문 비교]
```

---

## 10. Git 커밋 내역 (추가)

| 커밋 | 메시지 | 변경 파일 |
|------|--------|-----------|
| `36a5f2e` | ci: Docker 빌드 검증 추가 | 2개 |
| `b86bd27` | ci: dev 브랜치 push 트리거 추가 | 1개 |
| `e578086` | feat: 프롬프트 A/B 테스트 실험 프레임워크 추가 | 6개 |

### 커밋 3: `36a5f2e`
```
ci: Docker 빌드 검증 추가

- .github/workflows/ci.yml: docker job 추가
  - test/lint 통과 후 실행 (needs)
  - 이미지 빌드만 검증 (push 없음)
- Dockerfile: data/ 폴더 추가 (용어 사전 CSV)
```

### 커밋 4: `b86bd27`
```
ci: dev 브랜치 push 트리거 추가

- push: main, master, develop, dev
- pull_request: main, master
```

### 커밋 5: `e578086`
```
feat: 프롬프트 A/B 테스트 실험 프레임워크 추가

## 신규 파일
- experiments/run_experiment.py: A/B 테스트 러너
  - argparse CLI (-f term -a 0.1.0 -b 0.2.0)
  - 병렬 실행 (asyncio.gather)
  - JSON + Markdown 결과 리포트 생성
- experiments/test_cases/term_test_cases.json: 10개 테스트 케이스
- experiments/README.md: 사용법 및 출력 예시

## 프롬프트 버전 관리
- prompts/EXPERIMENTS.md: 실험 기록 및 메트릭 문서
- prompts/term/evaluate_0.2.0.md: Few-shot 예시 추가 버전
```

---

## 11. 현재 프로젝트 상태

### PartnersAI 기능 현황
| 기능 | 상태 | 엔드포인트 |
|------|------|-----------|
| Role-fit AI | ✅ 완료 | `POST /ai/rolefit/analyze` |
| Mindset Coach | ✅ 완료 | `POST /ai/mindset/coach` |
| Structure Mission | ✅ 완료 | `POST /ai/structure/evaluate` |
| Judgment Mission | ✅ 완료 | `POST /ai/judgment/evaluate` |
| Term Mission | ✅ 완료 | `POST /ai/term/evaluate` |
| 용어 랜덤 출제 | ✅ 완료 | `GET /ai/term/random` |

### 테스트 현황
- 총 36개 테스트 통과
- GitHub Actions CI 설정 완료 (pytest + ruff)

### 다음 작업 후보
- [ ] 다른 미션에도 랜덤 시나리오 출제 기능 추가
- [ ] 사용자별 진행 상황 저장 (DB 연동)
- [ ] 크레딧 시스템 구현
- [ ] 프론트엔드 연동 API 최적화

---

## 파일 변경 요약

| 파일 | 변경 유형 | 설명 |
|------|----------|------|
| `streamlit_app.py` | 수정 | 랜덤 출제 버튼, 사이드바 버그 수정 |
| `app/features/term/schemas.py` | 수정 | definition 필드 추가 |
| `app/features/term/service.py` | 수정 | format_prompt에 definition 전달 |
| `prompts/term/evaluate_0.1.0.md` | 수정 | 공식 정의 섹션 추가 |
| `app/main.py` | 수정 | Swagger 용어 사전 섹션 추가 |
| `README.md` | 수정 | 용어 사전, 프로젝트 구조 업데이트 |
| `tests/test_features/test_term.py` | 수정 | definition 테스트 추가 |
| `tests/test_api.py` | 수정 | definition API 테스트 추가 |
"""
[느낀 점]
1. 끝까지 최선을 다하자.

---

출력 양식:

# 📅 날짜: (예: 25.11.11 (화))

## 🧩 주요 업무
- 오늘 수행한 핵심 업무를 구체적으로 요약  
- 기술적 결과, 진행 상황, 산출물 등을 명시  

## 🎯 목표 정리
### 장기 목표
- 프로젝트의 중장기적 방향 또는 최종 지향점  
### 단기 목표
- 오늘 혹은 이번 주 달성 목표  

## ⚙️ 진행 및 이슈
- 진행 단계별 구체적 내용  
- 발생한 문제와 해결 과정  
- 미해결 과제 및 후속 조치  

## 🧠 느낀 점 및 개선
- 사용자 입력 기반으로 정리된 통찰, 개선 아이디어, 학습 내용  

## 🤝 협업 및 커뮤니케이션
- 회의, 보고, 협업 이슈, 의사소통 내용 정리  
- 논의된 결정사항 및 향후 조율 방향  

## 📚 참고 및 학습 내용
- 새로 학습하거나 참고한 기술·논문·문서  
- 업무 개선에 도움이 된 개념 또는 자료  

## 📈 성과 및 지표
- 정량적 성과(예: 정확도, 속도, 효율 등)  
- 수치가 없을 경우 주요 진척도를 서술  

## 🗓️ 내일 계획
- 다음 업무 목표 및 우선순위  
- 예상 리스크 및 대비책  

---

지침:
1. 전체 분량은 500~650단어 이내로 유지한다.  
2. 문장은 명사형·서술형으로 끝내며, 감정적 표현은 제외한다.  
3. 입력이 비어 있으면 아래 기본 내용을 자동으로 채운다.
4. 날짜는 월화수목금의 요일만 사용한다.

---

[기본 디폴트 예시]
- **업무 내용**: LangChain 실습 복습, 문서 분석 코드 개선, 팀 회의 참석  
- **느낀 점**: 구조화된 학습이 업무 이해에 도움됨. 반복 작업 효율 개선 필요.
```

