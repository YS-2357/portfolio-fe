---
태그: []
날짜: "2025-12-30"
이름: "25.12.30 (화)"
---

# 25.12.30 (화)


# 📅 날짜: 25.12.30 (화)


## 🧩 주요 업무


- 인톡파트너스 2.0 AI 서비스 미션 구조 재점검 및 **언어전환 미션의 핵심 역량 재정의** 수행함.

- 언어전환의 목표를 “문장 교정”이 아닌 **리스크 제거 + 상담 흐름 전진**으로 재설정하고, 전환 유형 **6종 분해 전략**을 확정함.

- PartnersAI 백엔드에서 **미션 통합 리팩토링**을 수행하여 Structure/Judgment 미션을 제거하고 Conversation 미션으로 통합함.

- 실험 프레임워크를 기능별 스크립트로 분리하고, 평균 점수 중심 평가의 한계를 보완하는 **신규 메트릭(in_range_rate, pass_match_rate, MAE, std_dev)**을 도입함.

- Term 프롬프트의 평가 오류 원인을 해결하기 위해 “참고 정보(평가 대상 아님)”와 “평가 대상”을 명확히 분리하고, 비응답 처리 규칙을 추가함.

- Rolefit 문항 선택지 순서를 “최악→최선”으로 통일하여 사용자 선택 편향을 줄이는 방향으로 개선함.

- 문서(README/Swagger/experiments/프롬프트 히스토리)를 최신화하고, Mindset 프롬프트 0.2.0 채택 근거를 실험 결과로 확정함.

- scriptmate-be 기반으로 Firestore 감시 구조, CLOVA Speech STT 구성, live_guide/live_sales 흐름을 조사하고 STT 품질 이슈에 대한 대안(Whisper 배치 처리)을 정리함.

## 🎯 목표 정리


### 장기 목표


- 인톡파트너스 2.0에서 미션 기반 평가를 **핵심 역량(리스크 제어·상담 전진·표현 전환)** 중심으로 재구성하고, 평가 기준을 실험/메트릭으로 관리 가능한 체계로 고정하는 목표 설정함.

- 백엔드 기능 구조를 “미션 단위 모듈 + 프롬프트 버전 + 실험 프레임워크 + CI”로 표준화하여 반복 개선 속도를 높이는 목표 설정함.

### 단기 목표


- Conversation 미션의 6종 평가 프롬프트(0.1.0 vs 0.2.0) A/B 테스트를 수행하고, 신규 메트릭으로 채택 버전을 확정하는 목표 설정함.

- Term/Rolefit 변경 사항에 대한 리그레션 테스트 및 실험 재검증을 통해 품질 기준선을 재설정하는 목표 설정함.

## ⚙️ 진행 및 이슈


- **기획(언어전환 미션)**

- **백엔드 구조 리팩토링**

- **실험 프레임워크 개선**

- **프롬프트/문항 개선**

- **이슈 및 후속**

## 🧠 느낀 점 및 개선


- 하루 단위로 완료 가능한 작업 단위를 명확히 정의하고, “기획→구현→실험→문서”를 같은 날에 닫는 운영 방식 필요함.

- 미션 통합/삭제 같은 큰 변경은 실험 프레임워크와 테스트케이스 정합성을 먼저 확보한 뒤 진행하는 절차적 안전장치 필요함.

- 언어전환 미션은 표현 교정이 아니라 “리스크를 낮추면서 다음 질문/행동을 끌어내는 능력”으로 평가해야 한다는 기준 확립함.

## 🤝 협업 및 커뮤니케이션


- 인톡파트너스 2.0 미션 구조 재정의 결과를 내부 공통 언어로 정리하고, 언어전환 미션의 역할을 핵심 평가축으로 상향 조정함.

- Swagger/README/프롬프트 히스토리 문서 최신화를 통해 팀 내 변경 사항 공유 비용을 낮추는 방향으로 정리함.

- scriptmate-be 조사 결과를 기반으로 STT 품질 이슈와 대체 방안(Whisper 배치 처리)을 공유 가능한 형태로 정리함.

## 📚 참고 및 학습 내용


- 미션 통합 설계 관점에서 “평가 기준(루브릭)–프롬프트–스키마–테스트”의 입력 계약 일치 원칙 재확인함.

- 실험 메트릭 설계에서 expected 기반 적중률/일치율/MAE/분산 지표를 도입하는 방식 학습함.

- Firestore 기반 실시간 감시 구조 및 CLOVA Speech gRPC STT 구성 흐름 파악함.

## 📈 성과 및 지표


- 미션 구조 변경 완료: Structure/Judgment 제거 및 Conversation 미션 추가, 관련 프롬프트/테스트/라우팅 정리 완료함.

- 실험 프레임워크 개선 완료: feature별 실험 스크립트 분리, 테스트케이스 구조 통일, 신규 메트릭 도입 완료함.

- Mindset 프롬프트 0.2.0 채택 근거 확보: 범위내 적중률 62.5%→75.0%, MAE 0.038→0.013 개선 결과 기록함.

- 문서 최신화 완료: README/Swagger/experiments/프롬프트 버전 히스토리 반영 완료함.

## 🗓️ 내일 계획


- Conversation 프롬프트 0.1.0 vs 0.2.0 A/B 테스트 실행 및 in_range_rate/pass_match_rate/MAE/std_dev 기준으로 채택 버전 결정함.

- Term 프롬프트 구조 개선 후 테스트케이스 재검증 및 비응답/경계값 케이스 확장함.

- Rolefit 문항 재테스트 수행 및 선택지 순서 통일 효과(오답 선택률 감소 여부) 확인함.

- pytest 커버리지 점검 후 리팩토링 영향 구간(Conversation/Term/Rolefit) 우선으로 테스트 보강함.

```markdown
당신은 ‘업무일지와 회고 정리 전문가’다.  
아래 사용자의 입력을 바탕으로 하루치 업무일지를 Markdown 형식으로 작성하라.  
입력이 비어 있으면 디폴트 예시 내용을 넣는다.  
결과는 실제 업무 문서에 기록 가능한 수준의 정확성·간결성을 유지하라.

---

입력 형식:
[업무 내용]
1. 기획 업무
"""
오늘 진행한 업무

인톡파트너스 2.0 AI 서비스 기획 구조 검토

전체 미션 구조(적합성 판단 / 사고·태도 / 언어전환 / 용어설명) 재점검

언어전환 미션을 핵심 역량 평가로 재정의

언어전환 미션 고도화 방향 수립

언어전환의 목적을 “문장 교정”이 아닌
리스크 제거 + 상담 진행을 전진시키는 언어 능력으로 정의

전환 유형 6종 분해 전략 확정
"""
2. 코드 업무
"""
# 2025-12-30 작업 일지

## 개요

PartnersAI 백엔드 대규모 리팩토링 및 프롬프트 최적화 작업 수행.
Structure/Judgment 미션을 제거하고 Conversation 미션으로 통합, 실험 프레임워크 개선 및 문서 최신화.

---

## 1. 미션 구조 변경

### 제거된 미션
- **Structure Mission** (`/ai/structure/evaluate`) - 상담 구조 설계 미션
- **Judgment Mission** (`/ai/judgment/evaluate`) - 위험 판단 미션

### 추가된 미션
- **Conversation Mission** (`/ai/conversation/evaluate`) - 고객 질문 응대 미션

### 변경된 파일
```
삭제:
- app/features/structure/
- app/features/judgment/
- prompts/structure/
- prompts/judgment/
- tests/test_features/test_structure.py
- tests/test_features/test_judgment.py

추가:
- app/features/conversation/
  - __init__.py
  - routes.py
  - schemas.py
  - service.py
- prompts/conversation/
  - evaluate_0.1.0.md (6종 평가)
  - evaluate_0.2.0.md (압축)
  - README.md
- tests/test_features/test_conversation.py
```

### Conversation 평가 기준 (6종)
| 차원 | 가중치 | 설명 |
|------|--------|------|
| empathy | 25% | 공감 표현 |
| question_redirect | 25% | 니즈 파악 질문 유도 |
| simple_language | 20% | 일상 언어 사용 |
| accuracy | 20% | 정확성 |
| naturalness | 10% | 자연스러움 |

---

## 2. 실험 프레임워크 개선

### 기존 문제점
- `run_experiment.py` 통합 스크립트 → 유지보수 어려움
- 메트릭이 "평균 점수"만 제공 → 의미 없음
- 테스트 케이스 구조 불일치

### 개선 내용

#### 2.1 개별 실험 스크립트
```
experiments/
├── exp_conversation.py
├── exp_mindset.py
├── exp_term.py
├── test_cases/
│   ├── conversation_test_cases.json
│   ├── mindset_test_cases.json
│   ├── rolefit_test_cases.json
│   └── term_test_cases.json
└── results/
```

#### 2.2 새로운 메트릭
| 메트릭 | 설명 |
|--------|------|
| `in_range_rate` | 점수가 expected.score_range 내에 있는 비율 |
| `pass_match_rate` | expected.passed와 실제 passed 일치율 |
| `mae` | 범위 이탈 시 경계까지 평균 거리 (낮을수록 좋음) |
| `std_dev` | 점수 분산 (0이면 모든 점수 동일 = 문제) |

#### 2.3 테스트 케이스 구조 통일
```json
{
  "id": "term_001",
  "term": "해약환급금",
  "user_explanation": "...",
  "expected": {
    "passed": true,
    "score_range": [0.7, 0.9]
  }
}
```

---

## 3. 프롬프트 개선

### 3.1 Term 프롬프트 구조 개선

**문제**: LLM이 "공식 정의"를 "사용자 설명"으로 오인하여 평가

**해결**: 섹션 분리 및 명시
```markdown
# 참고 정보 (평가 대상 아님)
- 보험 용어: {term}
- 공식 정의: {definition}

---

# 평가 대상
{user_explanation}
```

**비응답 처리 추가**:
- "모르겠음", "패스" 등 → `passed: false`, `score: 0.0`

### 3.2 버전 정리
| 미션 | 0.1.0 | 0.2.0 | 0.3.0 |
|------|-------|-------|-------|
| term | 기본 (구조개선) | 압축 | 삭제됨 |
| mindset | 기본 | 압축 (**채택**) | - |
| conversation | 6종 평가 | 압축 | - |

---

## 4. Rolefit 문항 개선

### 문제점
선택지 순서가 불규칙하여 사용자가 "2번이 무난해 보여서" 선택 → 실제로는 나쁜 답변인 경우 다수

### 해결
선택지 순서 통일 (version 0.2.0 → 0.3.0):
```
1 = 최악 (명백히 나쁨)
2 = 나쁨 (소극적/회피)
3 = 양호 (기본 수준)
4 = 최선 (모범 답안)
```

### 예시 (T3: 허위 기재 요청)
| 순서 | 답변 | 판정 |
|------|------|------|
| 1 | "시키는 대로 한다" | 최악 |
| 2 | "고객 요청이니 도와준다" | 나쁨 |
| 3 | "이번만 도와주고 다음엔 안 된다" | 나쁨 |
| 4 | "정확한 내용으로 기재해야 한다고 설명" | **최선** |

---

## 5. 문서 최신화

### README.md
- Structure/Judgment → Conversation 변경
- 프로젝트 구조에 experiments/, prompts/ 추가
- 엔드포인트 테이블 업데이트

### Swagger UI (main.py)
- 엔드포인트 명시 추가
- Role-fit 평가 차원 수정 (공감, 윤리, 문해, 규칙준수)
- Conversation 평가 기준 가중치 추가

### experiments/README.md
- 새 메트릭 설명 (in_range_rate, pass_match_rate, MAE, std_dev)
- 테스트 케이스 형식 문서화
- 실험 워크플로우 안내

### prompts/*/README.md
- 각 미션별 버전 히스토리 문서화
- 실험 결과 기록

---

## 6. 실험 결과

### Mindset 0.1.0 vs 0.2.0
| 메트릭 | 0.1.0 | 0.2.0 | 결과 |
|--------|-------|-------|------|
| 범위내 적중 | 62.5% | **75.0%** | 0.2.0 승 |
| MAE | 0.038 | **0.013** | 0.2.0 승 |

**결론**: mindset 기본 프롬프트를 0.2.0으로 변경

### 현재 프롬프트 설정 (config.py)
```python
prompt_rolefit: str = "rolefit/analyze_0.1.0.md"
prompt_mindset: str = "mindset/coach_0.2.0.md"  # 변경됨
prompt_term: str = "term/evaluate_0.1.0.md"
prompt_conversation: str = "conversation/evaluate_0.1.0.md"
```

---

## 7. 커밋 히스토리

| 커밋 | 설명 |
|------|------|
| `8e0de92` | refactor: Structure/Judgment 미션 제거, Conversation 미션 추가 |
| `698ba43` | docs: Swagger UI 설명 최신화 |
| `71682b3` | fix: rolefit 문항 선택지 순서 통일 |
| `5f3163e` | fix: term 프롬프트 구조 개선 및 0.3.0 삭제 |
| `cfc3321` | chore: mindset 기본 프롬프트 0.2.0으로 변경 |

---

## 8. 기타

### scriptmate-be 조사
- Firebase Firestore 사용 확인 (실시간 요청 감시)
- CLOVA Speech STT 클라이언트 분석
- live_guide_service.py / live_sales_service.py 분석
- STT 품질 이슈 논의 → Whisper 일괄 처리 권장

---

## 다음 작업 (TODO)

- [ ] Conversation 프롬프트 A/B 테스트 실행
- [ ] Term 프롬프트 테스트 (구조 개선 후)
- [ ] Rolefit 문항 재테스트 (순서 통일 후)
- [ ] 테스트 커버리지 확인 (pytest)
"""

[느낀 점]
1. 업무가 정해지면 하루 안에 끝내는 버릇을 갖자. 그 정도로 애정이 있는 일을 하자.

---

출력 양식:

# 📅 날짜: (예: 25.11.11 (화))

## 🧩 주요 업무
- 오늘 수행한 핵심 업무를 구체적으로 요약  
- 기술적 결과, 진행 상황, 산출물 등을 명시  

## 🎯 목표 정리
### 장기 목표
- 프로젝트의 중장기적 방향 또는 최종 지향점  
### 단기 목표
- 오늘 혹은 이번 주 달성 목표  

## ⚙️ 진행 및 이슈
- 진행 단계별 구체적 내용  
- 발생한 문제와 해결 과정  
- 미해결 과제 및 후속 조치  

## 🧠 느낀 점 및 개선
- 사용자 입력 기반으로 정리된 통찰, 개선 아이디어, 학습 내용  

## 🤝 협업 및 커뮤니케이션
- 회의, 보고, 협업 이슈, 의사소통 내용 정리  
- 논의된 결정사항 및 향후 조율 방향  

## 📚 참고 및 학습 내용
- 새로 학습하거나 참고한 기술·논문·문서  
- 업무 개선에 도움이 된 개념 또는 자료  

## 📈 성과 및 지표
- 정량적 성과(예: 정확도, 속도, 효율 등)  
- 수치가 없을 경우 주요 진척도를 서술  

## 🗓️ 내일 계획
- 다음 업무 목표 및 우선순위  
- 예상 리스크 및 대비책  

---

지침:
1. 전체 분량은 500~650단어 이내로 유지한다.  
2. 문장은 명사형·서술형으로 끝내며, 감정적 표현은 제외한다.  
3. 입력이 비어 있으면 아래 기본 내용을 자동으로 채운다.
4. 날짜는 월화수목금의 요일만 사용한다.

---

[기본 디폴트 예시]
- **업무 내용**: LangChain 실습 복습, 문서 분석 코드 개선, 팀 회의 참석  
- **느낀 점**: 구조화된 학습이 업무 이해에 도움됨. 반복 작업 효율 개선 필요.
```

